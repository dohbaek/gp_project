{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.4.10\n",
      "  latest version: 4.5.4\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes -c menpo scipy imageio opencv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load main.py\n",
    "import argparse, os\n",
    "from GAN import GAN\n",
    "from CGAN import CGAN\n",
    "from LSGAN import LSGAN\n",
    "from DRAGAN import DRAGAN\n",
    "from ACGAN import ACGAN\n",
    "from WGAN import WGAN\n",
    "from WGAN_GP import WGAN_GP\n",
    "from infoGAN import infoGAN\n",
    "from EBGAN import EBGAN\n",
    "from BEGAN import BEGAN\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import utils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS(object):\n",
    "    def __init__(self, name, epoch):\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = 64\n",
    "        self.dataset = 'celebA'\n",
    "        self.gpu_mode = True\n",
    "        self.lrG = 0.0002\n",
    "        self.lrD = 0.0002\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.999\n",
    "        \n",
    "        self.gan_type = name\n",
    "        self.save_dir = name + '/save'\n",
    "        self.result_dir = name + '/result'\n",
    "        self.log_dir = name + '/log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(gan, number):\n",
    "    if not os.path.exists(gan.model_name + '/dataset'):\n",
    "            os.makedirs(gan.model_name + '/dataset')\n",
    "    for x in range (0, number):\n",
    "        sample_z_ = Variable(torch.rand((gan.batch_size, gan.z_dim)).cuda(), volatile=True)\n",
    "        samples = gan.G(sample_z_)\n",
    "        samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        utils.save_images(samples[:1, :, :, :], [1, 1], gan.model_name + '/dataset/' + str(x) + '.png')\n",
    "        img = cv2.imread(gan.model_name + '/dataset/' + str(x) + '.png')\n",
    "        res = cv2.resize(img, dsize = (128, 128))\n",
    "        cv2.imwrite(gan.model_name + '/dataset/' + str(x) + '.png', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks architecture -------------\n",
      "generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=62, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=32768, bias=True)\n",
      "    (4): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 33853635\n",
      "discriminator(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=65536, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=32, out_features=65536, bias=True)\n",
      "    (4): BatchNorm1d(65536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 4397219\n",
      "-----------------------------------------------\n",
      "training start!!\n"
     ]
    }
   ],
   "source": [
    "began = BEGAN(ARGS('BEGAN', 1))\n",
    "began.train()\n",
    "generateDataset(began, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks architecture -------------\n",
      "generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=62, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=32768, bias=True)\n",
      "    (4): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 33853635\n",
      "discriminator(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 33693121\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torchvision-0.2.1-py2.7.egg/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "GAN.py:138: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.sample_z_ = Variable(torch.rand((self.batch_size, self.z_dim)).cuda(), volatile=True)\n",
      "GAN.py:188: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['D_loss'].append(D_loss.data[0])\n",
      "GAN.py:189: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.rfloss_hist['Real_loss'].append(D_real_loss.data[0])\n",
      "GAN.py:190: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.rfloss_hist['Fake_loss'].append(D_fake_loss.data[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GAN.py:201: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['G_loss'].append(G_loss.data[0])\n",
      "GAN.py:208: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.data[0], G_loss.data[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 100/1258] D_loss: 1.22059608, G_loss: 0.86929369\n",
      "Epoch: [ 1] [ 200/1258] D_loss: 0.64660525, G_loss: 1.45365715\n",
      "Epoch: [ 1] [ 300/1258] D_loss: 1.46539235, G_loss: 1.59674287\n",
      "Epoch: [ 1] [ 400/1258] D_loss: 0.67149341, G_loss: 1.30321872\n",
      "Epoch: [ 1] [ 500/1258] D_loss: 0.57986760, G_loss: 1.71078229\n",
      "Epoch: [ 1] [ 600/1258] D_loss: 0.51082963, G_loss: 1.85772204\n",
      "Epoch: [ 1] [ 700/1258] D_loss: 0.85690969, G_loss: 2.13028955\n",
      "Epoch: [ 1] [ 800/1258] D_loss: 0.35064447, G_loss: 2.02177715\n",
      "Epoch: [ 1] [ 900/1258] D_loss: 0.49272254, G_loss: 2.14792442\n",
      "Epoch: [ 1] [1000/1258] D_loss: 0.22073948, G_loss: 2.28951693\n",
      "Epoch: [ 1] [1100/1258] D_loss: 0.15245949, G_loss: 2.78948998\n",
      "Epoch: [ 1] [1200/1258] D_loss: 0.25777540, G_loss: 2.80938792\n",
      "Avg one epoch time: 216.78, total 1 epochs time: 216.82\n",
      "Training finish!... save training results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks architecture -------------\n",
      "generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=62, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=32768, bias=True)\n",
      "    (4): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 33853635\n",
      "discriminator(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 33693121\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WGAN.py:137: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.sample_z_ = Variable(torch.rand((self.batch_size, self.z_dim)).cuda(), volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WGAN.py:202: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['G_loss'].append(G_loss.data[0])\n",
      "WGAN.py:207: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['D_loss'].append(D_loss.data[0])\n",
      "WGAN.py:208: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.rfloss_hist['Real_loss'].append(D_real_loss.data[0])\n",
      "WGAN.py:209: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.rfloss_hist['Fake_loss'].append(D_fake_loss.data[0])\n",
      "WGAN.py:213: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.data[0], G_loss.data[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 100/1258] D_loss: -0.00469017, G_loss: -0.49838507\n",
      "Epoch: [ 1] [ 200/1258] D_loss: -0.00483161, G_loss: -0.49766797\n",
      "Epoch: [ 1] [ 300/1258] D_loss: -0.00477278, G_loss: -0.49725303\n",
      "Epoch: [ 1] [ 400/1258] D_loss: -0.00497580, G_loss: -0.49716249\n",
      "Epoch: [ 1] [ 500/1258] D_loss: -0.00487858, G_loss: -0.49703485\n",
      "Epoch: [ 1] [ 600/1258] D_loss: -0.00461361, G_loss: -0.49783999\n",
      "Epoch: [ 1] [ 700/1258] D_loss: -0.00482452, G_loss: -0.49692053\n",
      "Epoch: [ 1] [ 800/1258] D_loss: -0.00489399, G_loss: -0.49704403\n",
      "Epoch: [ 1] [ 900/1258] D_loss: -0.00467858, G_loss: -0.49713016\n",
      "Epoch: [ 1] [1000/1258] D_loss: -0.00461477, G_loss: -0.49727932\n",
      "Epoch: [ 1] [1100/1258] D_loss: -0.00465199, G_loss: -0.49732286\n",
      "Epoch: [ 1] [1200/1258] D_loss: -0.00471500, G_loss: -0.49725369\n",
      "Avg one epoch time: 144.42, total 1 epochs time: 144.51\n",
      "Training finish!... save training results\n",
      "---------- Networks architecture -------------\n",
      "generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=62, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=32768, bias=True)\n",
      "    (4): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 33853635\n",
      "discriminator(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=65536, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=32, out_features=65536, bias=True)\n",
      "    (4): BatchNorm1d(65536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 4397219\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BEGAN.py:147: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.sample_z_ = Variable(torch.rand((self.batch_size, self.z_dim)).cuda(), volatile=True)\n",
      "BEGAN.py:197: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['D_loss'].append(D_loss.data[0])\n",
      "BEGAN.py:198: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.rfloss_hist['Real_loss'].append(D_real_err.data[0])\n",
      "BEGAN.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.rfloss_hist['Fake_loss'].append(D_fake_err.data[0])\n",
      "BEGAN.py:212: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['G_loss'].append(G_loss.data[0])\n",
      "BEGAN.py:222: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  temp_k = temp_k.data[0]\n",
      "BEGAN.py:226: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.M = temp_M.data[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BEGAN.py:230: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.data[0], G_loss.data[0], self.M, self.k))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 100/1258] D_loss: 0.18011533, G_loss: 0.12307077, M: 0.19230118, k: 0.00080834\n",
      "Epoch: [ 1] [ 200/1258] D_loss: 0.11549648, G_loss: 0.14200228, M: 0.17087641, k: 0.00000000\n",
      "Epoch: [ 1] [ 300/1258] D_loss: 0.09940004, G_loss: 0.14384954, M: 0.16869955, k: 0.00000000\n",
      "Epoch: [ 1] [ 400/1258] D_loss: 0.09303849, G_loss: 0.14457451, M: 0.16783413, k: 0.00000000\n",
      "Epoch: [ 1] [ 500/1258] D_loss: 0.08889154, G_loss: 0.13920516, M: 0.16142803, k: 0.00000000\n",
      "Epoch: [ 1] [ 600/1258] D_loss: 0.08686692, G_loss: 0.13377894, M: 0.15549567, k: 0.00000000\n",
      "Epoch: [ 1] [ 700/1258] D_loss: 0.08275580, G_loss: 0.12496819, M: 0.14565715, k: 0.00000000\n",
      "Epoch: [ 1] [ 800/1258] D_loss: 0.07848619, G_loss: 0.11170336, M: 0.13132490, k: 0.00000000\n",
      "Epoch: [ 1] [ 900/1258] D_loss: 0.07833637, G_loss: 0.11020511, M: 0.12978920, k: 0.00000000\n",
      "Epoch: [ 1] [1000/1258] D_loss: 0.07566920, G_loss: 0.09519723, M: 0.11411453, k: 0.00000000\n",
      "Epoch: [ 1] [1100/1258] D_loss: 0.07736126, G_loss: 0.08672985, M: 0.10607017, k: 0.00000000\n",
      "Epoch: [ 1] [1200/1258] D_loss: 0.07371048, G_loss: 0.08769446, M: 0.10612208, k: 0.00000000\n",
      "Avg one epoch time: 203.72, total 1 epochs time: 203.79\n",
      "Training finish!... save training results\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(ARGS('GAN', 1))\n",
    "gan.train()\n",
    "generateDataset(gan, 200)\n",
    "\n",
    "wgan = WGAN(ARGS('WGAN', 1))\n",
    "wgan.train()\n",
    "generateDataset(wgan, 200)\n",
    "\n",
    "began = BEGAN(ARGS('BEGAN', 1))\n",
    "began.train()\n",
    "generateDataset(began, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
